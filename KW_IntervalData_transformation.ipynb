{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AlexandriaVA-Energy-Office/dominion-interval-data/blob/main/KW_IntervalData_transformation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J_oTn4P8u5l8"
      },
      "source": [
        "This script is to be used for cleaning multiple column-organized interval data tables, transforming them, and appending them into a single, row-organized, batched import file for upload into EnergyCAP. It is built to accommodate both historic, inconsistently formatted files as well as raw, newly downloaded files from Dominion*.\n",
        "\n",
        "This script is intended for demand/kW data files.\n",
        "\n",
        "(*historic files will be read in as .xlsx, while newly downloaded files read in as .csv; need to adjust commented code accordingly when reading in file)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JqaSeodxvG3_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a30f39f2-a4c7-4f0b-e683-f302c5a026ab"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xxANrJToETL7"
      },
      "source": [
        "# All uploaded files, installed packages, variables, etc. clear after 90 min. idle time or 12 hours of use\n",
        "\n",
        "import pandas as pd\n",
        "from google.colab import drive\n",
        "from google.colab import files\n",
        "import os\n",
        "\n",
        "appended_data=pd.DataFrame()\n",
        "path='/content/drive/MyDrive/KW_IntDataFiles'\n",
        "\n",
        "for WorkingFile in os.listdir(path):\n",
        "# Use below two lines if this is historic file, remove other \"intdata_OG\" line.    \n",
        "    #xlsx = pd.ExcelFile(f\"{path}/{WorkingFile}\")\n",
        "    #intdata_OG = pd.read_excel(xlsx,'history-kw')\n",
        "# read in raw csv file into new dataframe, setting standard column length at 51. No header, assuming raw file.\n",
        "    intdata_OG = pd.read_csv(f\"{path}/{WorkingFile}\",header=None,names=list(range(51)))\n",
        "# use os.rename function to rename each raw file to its account number, for easy future reference.\n",
        "    source = path+'/'+WorkingFile\n",
        "    newname = str(intdata_OG.iat[0,0])\n",
        "    destination = path+'/'+newname+\".csv\"\n",
        "    os.rename(source,destination)\n",
        "# drop columns after 48 h-h increments;remove empty rows\n",
        "    stripcolumns = intdata_OG.iloc[:,0:51]\n",
        "    newfile = stripcolumns.dropna(axis=0,how='all')\n",
        "# add column headers to raw file; does not affect files with existing header\n",
        "    newfile.columns = [\"account number\",\"Recorder ID\",\"Date\",\"12:30 AM\",\"1:00 AM\",\"1:30 AM\",\"2:00 AM\",\"2:30 AM\",\"3:00 AM\",\"3:30 AM\",\"4:00 AM\",\"4:30 AM\",\n",
        "                      \"5:00 AM\",\"5:30 AM\",\"6:00 AM\",\"6:30 AM\",\"7:00 AM\",\"7:30 AM\", \"8:00 AM\",\"8:30 AM\",\"9:00 AM\",\"9:30 AM\",\"10:00 AM\",\"10:30 AM\",\"11:00 AM\",\n",
        "                      \"11:30 AM\",\"12:00 PM\",\"12:30 PM\",\"1:00 PM\",\"1:30 PM\",\"2:00 PM\",\"2:30 PM\",\"3:00 PM\",\"3:30 PM\",\"4:00 PM\",\"4:30 PM\",\"5:00 PM\",\"5:30 PM\",\n",
        "                      \"6:00 PM\",\"6:30 PM\",\"7:00 PM\",\"7:30 PM\",\"8:00 PM\",\"8:30 PM\",\"9:00 PM\",\"9:30 PM\",\"10:00 PM\",\"10:30 PM\",\"11:00 PM\",\"11:30 PM\",\"12:00 AM\"]\n",
        "# convert column ordered data into rows, adding new \"Time\" and \"Demand\" columns\n",
        "    reformatted = pd.melt(newfile,id_vars=[\"account number\",\"Recorder ID\", \"Date\"],\n",
        "                          value_vars=[\"12:30 AM\",\"1:00 AM\",\"1:30 AM\",\"2:00 AM\",\"2:30 AM\",\"3:00 AM\",\"3:30 AM\",\"4:00 AM\",\n",
        "                                      \"4:30 AM\",\"5:00 AM\",\"5:30 AM\",\"6:00 AM\",\n",
        "                                      \"6:30 AM\",\"7:00 AM\",\"7:30 AM\", \"8:00 AM\",\n",
        "                                      \"8:30 AM\",\"9:00 AM\",\"9:30 AM\",\"10:00 AM\",\"10:30 AM\",\"11:00 AM\",\"11:30 AM\",\"12:00 PM\",\n",
        "                                      \"12:30 PM\",\"1:00 PM\",\"1:30 PM\",\"2:00 PM\",\"2:30 PM\",\"3:00 PM\",\"3:30 PM\",\"4:00 PM\",\n",
        "                                      \"4:30 PM\",\"5:00 PM\",\"5:30 PM\",\"6:00 PM\",\"6:30 PM\",\"7:00 PM\",\"7:30 PM\",\"8:00 PM\",\"8:30 PM\",\n",
        "                                      \"9:00 PM\",\"9:30 PM\",\"10:00 PM\",\"10:30 PM\",\"11:00 PM\",\"11:30 PM\",\"12:00 AM\"],\n",
        "                          var_name=\"Time\",value_name=\"Demand\")\n",
        "# Add new \"Use\" column; switch column order; drop \"Recorder ID\" column; delete blank \"account number\" rows    \n",
        "    reformatted[\"Demand\"] = reformatted[\"Demand\"].apply(pd.to_numeric,errors='coerce').fillna(0)\n",
        "    reformatted[\"Use\"] = reformatted[\"Demand\"] * 0.5\n",
        "    column_titles = [\"account number\",\"Recorder ID\",\"Date\",\"Time\",\"Demand\",\"Use\"]\n",
        "    reformatted = reformatted.reindex(columns=column_titles)\n",
        "    reformatted1 = reformatted.drop([\"Recorder ID\"], axis=1)\n",
        "    finaltable = reformatted1.dropna(axis=0,subset=['account number'])\n",
        "# Remove timestamp from date; change account number from float to int; convert non-numeric values to 0\n",
        "    finaltable['Date'] = pd.to_datetime(finaltable['Date']).dt.date\n",
        "    finaltable['account number'] = finaltable['account number'].astype(int)\n",
        "    appended_data=appended_data.append(finaltable)\n",
        "    print(f\"{WorkingFile}\")\n",
        "appended_data.to_csv('/content/drive/MyDrive/KW_IntDataFiles/EnergyCAPupload.csv',index=False) \n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}